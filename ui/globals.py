from streamlit import session_state as ses
import streamlit as st
import os

LIB_DIR = '.'
EXPORT_DIR = './data/output'
REGEX = f'{EXPORT_DIR}/Regex.txt'
MAP = f'{EXPORT_DIR}/Map.txt'
CODE = f'{EXPORT_DIR}/Code.txt'
BNF = f'{EXPORT_DIR}/BNF.txt'
GRAMS = f'{EXPORT_DIR}/Grams.txt'
TABLE = f'{EXPORT_DIR}/Table.txt'
TREE = f'{EXPORT_DIR}/Tree.txt'
LEX = f'{EXPORT_DIR}/Lex.lex'
LEXC = f'{EXPORT_DIR}/Lexer.c'
COMPILER = 'g++'
REGEXER = './bin/æ­£åˆ™è¡¨è¾¾å¼åˆ†æå™¨'
LEXER = './bin/è¯æ³•åˆ†æå™¨'
LALRER = './bin/LALR(1)åˆ†æå™¨'
PARSER = './bin/è¯­æ³•åˆ†æå™¨'
INTERMER = './bin/ä¸­é—´ä»£ç åˆ†æå™¨'

os.makedirs(EXPORT_DIR, exist_ok=True)
RULE1 = [r'1ï¸âƒ£ å¦‚æœä¸æ­£åˆ™è¡¨è¾¾å¼ç¬¦å·å†²çª(+ã€|ã€(ã€)ã€*ã€?ã€~)ï¼Œç”¨\è¿›è¡Œè½¬ä¹‰(å¦‚\+)',
         r'2ï¸âƒ£ å­—ç¬¦é›†åˆæ— éœ€å‰ç¼€_ï¼Œå¦‚æœè¦è¡¨ç¤ºå®é™…å‡å·éœ€è¦è½¬ä¹‰(å³\-)',
         '3ï¸âƒ£ å¤§ç±»ç¼–ç æ­£åˆ™å¼å‰ç¼€ä¸º1ä¸ª_ï¼Œå¯¹æ•´ä¸ªæ­£åˆ™å¼ç¼–1ä¸ªå·',
         '4ï¸âƒ£ å­ç±»ç¼–ç æ­£åˆ™å¼å‰ç¼€ä¸º2ä¸ª_ï¼ŒæŒ‰|åˆ†å¼€ç‹¬ç«‹ç¼–å·å„ä¸ªå•è¯',
         '5ï¸âƒ£ è‹¥æ­£åˆ™å¼ä¸éœ€è¦ç¼–ç (å¦‚æ³¨é‡Š)ï¼Œåˆ™å‰ç¼€ä¸º1ä¸ª_åŠ 1ä¸ª!ï¼Œå³_!',
         '6ï¸âƒ£ ~è¡¨ç¤ºä»»æ„å­—ç¬¦ï¼Œç©ºæ ¼å’Œåˆ¶è¡¨ç¬¦ä¼šè¢«ä¸¢å¼ƒå¤„ç†ï¼Œè¾“å…¥æ— æ•ˆ']
RULE2 = ['1ï¸âƒ£ æ¯ä¸ªæ–‡æ³•Tokenä¹‹é—´è¦ç”¨ç©ºæ ¼åˆ†éš”(->å‰åå¯ä»¥æ²¡æœ‰ç©ºæ ¼)',
         '2ï¸âƒ£ è¾“å…¥çš„æ–‡æ³•è§„åˆ™åº”ç¡®ä¿æœ‰ç»Ÿä¸€çš„å½’çº¦å‡ºå£ï¼Œå³æ— éœ€å†æ‰©å……å¼€å§‹æ–‡æ³•']
RULE3 = ['1ï¸âƒ£ ç¬¬iè¡Œçš„è¾“å…¥æ˜¯ç¬¬iä¸ªæ–‡æ³•è§„åˆ™çš„è¯­æ³•æ ‘ç»“æ„',
         '2ï¸âƒ£ è¾“å…¥çš„æ•°å­—ä»£è¡¨æ–‡æ³•è§„åˆ™ä¸­Tokençš„ä¸‹æ ‡ï¼Œå¯åœ¨è¾“å‡ºä¸­å¯¹åº”æŸ¥æ‰¾',
         '3ï¸âƒ£ æ¯è¡Œçš„ç¬¬ä¸€ä¸ªæ•°å­—è¡¨ç¤ºä½œä¸ºæ ¹èŠ‚ç‚¹çš„Tokenä¸‹æ ‡',
         '4ï¸âƒ£ ä¹‹åç©ºæ ¼åˆ†éš”ï¼Œè¾“å…¥è‹¥å¹²ä¸ªæ•°å­—å¯¹x-yï¼Œå¤šä¸ªæ•°å­—å¯¹é—´ä¹Ÿç”¨ç©ºæ ¼åˆ†éš”',
         '5ï¸âƒ£ æ•°å­—å¯¹x-yè¡¨ç¤ºä¸‹æ ‡xçš„Tokenæ˜¯ä¸‹æ ‡yçš„çˆ¶èŠ‚ç‚¹']
INFO = {'âœï¸å§“å': 'é»„ä¿ŠéŠ“', 'ğŸ«ç­çº§': '2022è®¡ç§‘2', 'ğŸ†”å­¦å·': '20222131035', 'ğŸ’»å†…æ ¸ç¼–ç¨‹è¯­è¨€': 'C/C++',
        'ğŸ¨UIè®¾è®¡æ¡†æ¶': 'Streamlit'}
KEYS = [
    'txt1', 'lc1', 'NFA', 'DFA', 'MDFA', 'MDFAG', 'Lexer', 'rankdir',
    'txt2', 'lc2', 'Lex',
    'txt3', 'lc3', 'grams', 'Grams', 'First', 'Follow', 'LRDFA', 'LADFA', 'STB', 'DTB',
    'txt4', 'lc4', 'Trees',
    'txt5', 'lc5', 'interm', 'TreeList', 'TreeMap', 'Steps', 'K', 'Interm'
]


def decode(data):
    try:
        text = data.decode('utf-8')
    except UnicodeDecodeError:
        text = data.decode('gbk')
    return text.replace('\r', '')  # å»é™¤\ræ¢è¡Œç¬¦(é¿å…é”™è¯¯è¯»å…¥)


def read(path):
    with open(path, 'rb') as f:
        data = f.read()
    return decode(data)


def save_text(text, path):
    with open(path, 'w', encoding='utf-8') as f:
        f.write(text)


@st.dialog('ä¿å­˜æ–‡æœ¬æ¡†å†…å®¹ä¸ºæ–‡æœ¬æ–‡ä»¶')
def save_web_text(text):
    col1, col2 = st.columns([2, 1], vertical_alignment='bottom')
    name = col1.text_input('è¾“å…¥æ–‡ä»¶å', value='.txt').strip()
    col2.download_button('ä¸‹è½½', icon='ğŸ“¥', type='primary', use_container_width=True, file_name=name, data=text)


def input_module(page, content, label='å¼€å§‹åˆ†æ', icon='ğŸ§‘â€ğŸ’»'):
    st.subheader('è¾“å…¥')
    col1, col2 = st.columns([2, 1])
    fu = col2.file_uploader('ğŸ“¤ä¸Šä¼ æ–‡ä»¶')
    load = col2.button('åŠ è½½æ–‡ä»¶', icon='ğŸ—ƒï¸', disabled=not fu, use_container_width=True)
    save = col2.button('ä¿å­˜æ–‡ä»¶', icon='ğŸ’¾', use_container_width=True)
    start = col2.button(label, icon=icon, type='primary', use_container_width=True)
    if load:
        ses[f'txt{page}'] = decode(fu.read())
    txt = col1.text_area(f'âŒ¨ï¸è¾“å…¥{content}', key=f'txt{page}', height=200).strip()
    if save:
        save_web_text(txt)
    col3 = col1.columns(2)
    if col3[0].checkbox('ğŸ”¡å¿½ç•¥å¤§å°å†™', key=f'lc{page}'):
        txt = txt.lower()
    st.divider()
    return col1, col3[1], start, txt
